# ğŸ§  NeuroTriple-Lab

> **Laboratoire PÃ©dagogique de RÃ©seaux de Neurones**
> DÃ©montrer que plus on entraÃ®ne une IA, plus elle est prÃ©cise dans ses rÃ©ponses.

---

## ğŸ“‹ Description

**NeuroTriple-Lab** est un projet Ã©ducatif interactif qui utilise un rÃ©seau de neurones simple pour apprendre la fonction mathÃ©matique `f(x) = 3x` (tripler un nombre).

Le but principal est de **dÃ©montrer de maniÃ¨re visuelle et mesurable** que :

- âœ… **Plus on augmente le nombre d'epochs** (itÃ©rations d'entraÃ®nement), plus le modÃ¨le est prÃ©cis
- âœ… **Plus on ajoute de couches intermÃ©diaires** (profondeur du rÃ©seau), plus le modÃ¨le peut apprendre efficacement
- âœ… L'architecture et la durÃ©e d'entraÃ®nement sont des facteurs clÃ©s de la performance d'une IA

---

## ğŸ¯ Concept de Base

Le code original est simple : un rÃ©seau de neurones reÃ§oit des nombres en entrÃ©e et doit apprendre Ã  prÃ©dire leur triple.

```python
# DonnÃ©es d'entraÃ®nement
entree = [1, 2, 3, 4, 5]     # Nombres en entrÃ©e
sortie = [3, 6, 9, 12, 15]   # Le triple (rÃ©sultat attendu)
```

Le rÃ©seau n'a **aucune connaissance prÃ©alable** de la multiplication. Il apprend uniquement Ã  partir des exemples fournis, en ajustant ses poids internes Ã  chaque epoch.

---

## ğŸš€ 5 FonctionnalitÃ©s PÃ©dagogiques

### 1. ğŸ“Š Comparaison du Nombre d'Epochs
EntraÃ®ne le mÃªme modÃ¨le avec diffÃ©rents nombres d'epochs (ex: 10, 50, 100, 500, 1000, 3000) et compare la prÃ©cision obtenue. GÃ©nÃ¨re un graphique montrant la courbe de loss et l'erreur finale.

**Ce que vous apprenez** : L'impact direct du nombre d'itÃ©rations sur la qualitÃ© de l'apprentissage.

### 2. ğŸ—ï¸ Comparaison des Architectures
Teste diffÃ©rentes profondeurs de rÃ©seau :
- Simple : 1 couche, 8 neurones
- Moyenne : 1 couche, 64 neurones
- Profonde : 3 couches (128â†’64â†’32)
- TrÃ¨s profonde : 5 couches (256â†’128â†’64â†’32â†’16)

**Ce que vous apprenez** : Comment le nombre de couches et de neurones influence la capacitÃ© d'apprentissage.

### 3. ğŸ“ˆ Visualisation de l'Apprentissage
Affiche en dÃ©tail la courbe d'apprentissage (loss) avec trois graphiques :
- Courbe de loss complÃ¨te
- Courbe en Ã©chelle logarithmique
- PrÃ©dictions du modÃ¨le vs valeurs rÃ©elles

**Ce que vous apprenez** : Comment le modÃ¨le rÃ©duit progressivement son erreur au fil de l'entraÃ®nement.

### 4. ğŸ“‹ Tableau de PrÃ©cision DÃ©taillÃ©
Combine diffÃ©rents epochs ET architectures pour produire un tableau comparatif complet avec temps d'entraÃ®nement, erreur absolue et statut de qualitÃ©.

**Ce que vous apprenez** : La relation entre complexitÃ© du modÃ¨le, durÃ©e d'entraÃ®nement et prÃ©cision finale.

### 5. ğŸ”¬ Mode ExpÃ©rimentation AutomatisÃ©e
Lance une batterie complÃ¨te de tests (16 combinaisons) et produit un classement du meilleur au moins bon, avec un graphique rÃ©capitulatif.

**Ce que vous apprenez** : Comment trouver systÃ©matiquement la meilleure configuration pour un problÃ¨me donnÃ©.

### ğŸ® Mode Interactif (Bonus)
AprÃ¨s l'entraÃ®nement, entrez n'importe quel nombre et voyez la prÃ©diction de l'IA en temps rÃ©el, avec l'erreur par rapport Ã  la valeur exacte.

---

## ğŸ’» Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Ã‰tapes

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/thierrymaesen/NeuroTriple-Lab.git

# 2. AccÃ©der au dossier
cd NeuroTriple-Lab

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer le programme
python neurotriplelab.py
```

---

## ğŸ“– Utilisation

Au lancement, un menu interactif s'affiche :

```
  MENU PRINCIPAL
  ----------------------------------------
  1. Comparer diffÃ©rents nombres d'Epochs
  2. Comparer diffÃ©rentes Architectures
  3. Visualiser l'Apprentissage
  4. Tableau de PrÃ©cision DÃ©taillÃ©
  5. Mode ExpÃ©rimentation AutomatisÃ©e
  6. Mode Interactif (tester le modÃ¨le)
  0. Quitter
  ----------------------------------------
  Votre choix :
```

Choisissez une option en tapant le numÃ©ro correspondant. Chaque fonctionnalitÃ© vous guide pas Ã  pas et vous permet de personnaliser les paramÃ¨tres (nombre d'epochs, etc.).

---

## ğŸ“Š Exemples de RÃ©sultats

### Impact des Epochs sur la PrÃ©cision

| Epochs | Erreur Moyenne | QualitÃ© |
|--------|---------------|---------|
| 10     | ~150.0000     | Insuffisant |
| 50     | ~25.0000      | Moyen |
| 100    | ~8.0000       | Bon |
| 500    | ~0.5000       | TrÃ¨s bon |
| 1000   | ~0.0500       | Excellent |
| 3000   | ~0.0010       | Excellent |

> âš¡ **Conclusion** : Avec 10 epochs, l'IA se trompe Ã©normÃ©ment. Avec 3000 epochs, elle est quasi parfaite !

---

## ğŸ§© Comment Ã§a marche ?

### Le RÃ©seau de Neurones

```
EntrÃ©e (x) â†’ [Couche 1: N neurones] â†’ [Couche 2: N neurones] â†’ ... â†’ Sortie (3x)
```

1. **EntrÃ©e** : Un nombre (ex: 7)
2. **Couches cachÃ©es** : Traitent l'information avec des poids et des biais
3. **Sortie** : La prÃ©diction du triple (ex: 21.0003)
4. **Loss** : L'erreur entre la prÃ©diction et la rÃ©alitÃ©
5. **Optimisation** : L'algorithme Adam ajuste les poids pour rÃ©duire la loss
6. **Epochs** : Nombre de fois que le rÃ©seau voit toutes les donnÃ©es

### Pourquoi plus d'epochs = plus de prÃ©cision ?

Ã€ chaque epoch, le rÃ©seau ajuste lÃ©gÃ¨rement ses poids pour rÃ©duire l'erreur. C'est comme un Ã©lÃ¨ve qui s'amÃ©liore en pratiquant :
- **10 epochs** = L'Ã©lÃ¨ve a lu le cours une fois â†’ rÃ©sultats mÃ©diocres
- **1000 epochs** = L'Ã©lÃ¨ve a pratiquÃ© intensivement â†’ rÃ©sultats excellents

---

## ğŸ“ Structure du Projet

```
NeuroTriple-Lab/
â”œâ”€â”€ neurotriplelab.py    # Script principal avec les 5 fonctionnalitÃ©s
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ README.md            # Ce fichier
â”œâ”€â”€ LICENSE              # Licence MIT
â””â”€â”€ .gitignore           # Fichiers ignorÃ©s par Git
```

### Fichiers gÃ©nÃ©rÃ©s aprÃ¨s exÃ©cution (graphiques)
```
â”œâ”€â”€ comparaison_epochs.png           # Graphique fonctionnalitÃ© 1
â”œâ”€â”€ comparaison_architectures.png    # Graphique fonctionnalitÃ© 2
â”œâ”€â”€ visualisation_apprentissage.png  # Graphique fonctionnalitÃ© 3
â””â”€â”€ experimentation_complete.png     # Graphique fonctionnalitÃ© 5
```

---

## ğŸ”§ DÃ©pendances

| Package | Version | RÃ´le |
|---------|---------|------|
| TensorFlow | â‰¥ 2.10.0 | Framework de deep learning (Keras) |
| NumPy | â‰¥ 1.21.0 | Calculs numÃ©riques |
| Matplotlib | â‰¥ 3.5.0 | GÃ©nÃ©ration des graphiques |

> ğŸ’¡ **Note** : Le programme fonctionne mÃªme sans matplotlib (les graphiques seront simplement dÃ©sactivÃ©s).

---

## ğŸ“ Pour Aller Plus Loin

Voici des idÃ©es pour approfondir votre comprÃ©hension :

1. **Modifier les donnÃ©es** : Changez la fonction cible (ex: f(x) = 2x + 1 ou f(x) = xÂ²)
2. **Ajouter du bruit** : Ajoutez des erreurs alÃ©atoires dans les donnÃ©es d'entraÃ®nement
3. **Tester d'autres optimiseurs** : Remplacez adam par sgd ou rmsprop
4. **Varier le learning rate** : Modifiez la vitesse d'apprentissage
5. **Ajouter de la rÃ©gularisation** : Testez le dropout ou la rÃ©gularisation L2

---

## ğŸ“œ Licence

Ce projet est sous licence **MIT** - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commiter vos changements
4. Pousser la branche
5. Ouvrir une Pull Request

---

<p align="center">
  <strong>ğŸ§  Plus on entraÃ®ne, plus l'IA est prÃ©cise ! ğŸ¯</strong>
</p>
